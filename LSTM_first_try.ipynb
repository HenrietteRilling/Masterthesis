{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25901788",
   "metadata": {},
   "source": [
    "# LSTM trial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea5582",
   "metadata": {},
   "source": [
    "Architecture adopted from https://cnvrg.io/pytorch-lstm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9875b2b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfea5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from Data_loader import get_WL_data, get_prcp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111be51",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "WL, _, station_name_to_id, _ = get_WL_data(r'C:\\Users\\henri\\Documents\\Universität\\Masterthesis\\DMI_data\\Data_WL')\n",
    "prcp=get_prcp_data(r'C:\\Users\\henri\\Documents\\Universität\\Masterthesis\\DMI_data\\SVK', r'C:\\Users\\henri\\Documents\\Universität\\Masterthesis\\DMI_data\\DMI_Climate_Data_prcp', join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b180e3b",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed6bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers from WL data with z-score\n",
    "#calculate z-score\n",
    "zscore=(WL-WL.mean())/WL.std()\n",
    "#threshhold for detecting outliers\n",
    "threshold=3\n",
    "WL_wo_anom= WL \n",
    "for col in WL.columns:\n",
    "    WL_wo_anom[col][np.abs(zscore[col])>threshold]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cf072",
   "metadata": {},
   "source": [
    "Get data for test station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb674a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_station='ns Uldumkær'\n",
    "test_id=station_name_to_id.get(test_station)\n",
    "test_prcp='05225'\n",
    "X_WL=WL_wo_anom[[test_id]]\n",
    "X_prcp=prcp[[test_prcp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc413e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that only period in which sensor data is available is used\n",
    "X_WL=X_WL[(X_WL.index>X_WL.first_valid_index())&(X_WL.index<X_WL.last_valid_index())]\n",
    "X_prcp=X_prcp[(X_prcp.index>X_prcp.first_valid_index())&(X_prcp.index<X_prcp.last_valid_index())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d761af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge precipitation and WL data, select overlapping timeperiod\n",
    "X=pd.concat([X_WL, X_prcp], axis=1).loc[X_WL.index.intersection(X_prcp.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e90fe3",
   "metadata": {},
   "source": [
    "#### Split in Train and test data\n",
    "There is data available from '2011-11-09 11:00:00' to '2023-08-08 23:00:00' so in total 10 complete years of data. <br> \n",
    "In order to have complete seasonality in the data it makes sense to keep complete years in both the test and the train dataframes.\n",
    "<br>\n",
    "For the beginning I arbitrarily split the data in 7  years for training, 2 years for test and 1 year for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7dfdfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X['2011-01-01':'2018-12-31']\n",
    "X_test=X['2019-01-01':'2021-12-31']\n",
    "X_val=X['2022-01-01':'2022-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62443788",
   "metadata": {},
   "source": [
    "#### Standardization, normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4fa579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale and normalise such that all data has a range between [0,1]\n",
    "mm=MinMaxScaler()\n",
    "X_train_mm=mm.fit_transform(X_train)\n",
    "X_test_mm=mm.fit_transform(X_test)\n",
    "X_val_mm=mm.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e28760",
   "metadata": {},
   "source": [
    "### Data preparation for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00841d14",
   "metadata": {},
   "source": [
    "#### Get Windowed data with Philipps code\n",
    "Code creates batches of windowed data such that it can be used as an input in the LSTM.<br>\n",
    "Input to window code must have format [time,...,features], that's already the format we get out of the scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5e335254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4be413a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_labelled_window(windowed_data, horizon: int):\n",
    "    \"\"\"Create labels for windowed dataset\n",
    "    Input: [0, 1, 2, 3, 4, 5] and horizon=1\n",
    "    Output: ([0, 1, 2, 3, 4], [5])\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        time series to be labelled\n",
    "    horizon : int\n",
    "        the horizon to predict\n",
    "    \"\"\"\n",
    "    return windowed_data[:, :-horizon], windowed_data[:, -horizon:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "171a992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_dataset_from_array(data, window_size, horizon, stride=1, label_indices: list=None):\n",
    "    # Adapted from https://towardsdatascience.com/fast-and-robust-sliding-window-vectorization-with-numpy-3ad950ed62f5\n",
    "    # and https://www.mlq.ai/time-series-tensorflow-windows-horizons/\n",
    "    \"\"\"Creates windows and labels\n",
    "    Input data must have format [time, ..., features], where ... can be e.g. lat and lon.\n",
    "    Outputs have format [batch, time, ..., feature]. Number of features can vary depending on label_indices.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple(array, array)\n",
    "        Windows and labels with shapes [batch, time, ..., feature]\n",
    "    \"\"\"\n",
    "    # Create window of the specific size. Add horizon for to include labels.\n",
    "    window_step = np.expand_dims(np.arange(window_size + horizon), axis=0)\n",
    "    # Create the timesteps. subtract window_size and horizon to get equal length windows and subtract 1 to account for\n",
    "    # 0-indexing\n",
    "    time_step = np.expand_dims(\n",
    "        np.arange(data.shape[0] - (window_size + horizon - 1), step=stride), axis=0\n",
    "    ).T\n",
    "\n",
    "    # Create the window indexex\n",
    "    window_indexes = window_step + time_step\n",
    "\n",
    "    # Get the windows from the data in [batch, time, ..., features]\n",
    "    windowed_data = data[window_indexes]\n",
    "\n",
    "    # Split windows and labels\n",
    "    windows, labels = _get_labelled_window(windowed_data, horizon)\n",
    "\n",
    "    # Select only the labels we need\n",
    "    if label_indices is not None:\n",
    "        assert (\n",
    "            type(label_indices) == list\n",
    "        ), f\"label_indices needs to be list[int], but is {type(label_indices)}\"\n",
    "        labels = labels[..., label_indices]\n",
    "\n",
    "    return windows, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c621e",
   "metadata": {},
   "source": [
    "Dimensions of input + outputs:<br>\n",
    "\n",
    "**input**<br>\n",
    "input: [Time, F] <br>\n",
    "\n",
    "**window output**<br>\n",
    "features: [Time - S, S, F]<br>\n",
    "labels: [Time - S, H, F] <br>\n",
    "\n",
    "**data_loader output**<br>\n",
    "input_data: [B, S, F]<br>\n",
    "target_data: [B, H, F]<br>\n",
    "\n",
    "with B=Batchsize, S=Window Size (=Nr of timesteps chosen as input), H=Horizon (nr. of timesteps model will predict), F=nr. of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5581bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=10\n",
    "horizon=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cc7c2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get input and targets in batches with 10 timesteps input and predict the next timestep t+1, prcp data is only important for input, therefore label\n",
    "features, labels = timeseries_dataset_from_array(X_train_mm, window_size, horizon, label_indices=[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "16821df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62629, 2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mm.shape #shape:(nr of timesteps, nr of inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b14d0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62619, 10, 2)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "eb0409f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62619, 1, 1)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "89e862d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.tensor(features), torch.tensor(labels)) # insert into tensor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a3115b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True) # insert dataset into data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "290eca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data, target_data = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d3e927f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 2])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2d78dd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 1])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7609e9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31837381, 0.        ],\n",
       "       [0.31731785, 0.        ],\n",
       "       [0.31731785, 0.        ],\n",
       "       ...,\n",
       "       [0.40390707, 0.        ],\n",
       "       [0.4032031 , 0.        ],\n",
       "       [0.40214713, 0.        ]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ef29a",
   "metadata": {},
   "source": [
    "### LSTM architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0b720",
   "metadata": {},
   "source": [
    "Definition of the LSTM model and forward pass of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7303ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194e24f",
   "metadata": {},
   "source": [
    "Definition of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6fac48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000 #1000 epochs\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "\n",
    "input_size = 2 #number of features\n",
    "hidden_size = 2 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 #number of output classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34527c88",
   "metadata": {},
   "source": [
    "Instantiate  the class LSTM1 object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2bc4bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, window_size) #our lstm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "033d63c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM1(\n",
      "  (lstm): LSTM(2, 2, batch_first=True)\n",
      "  (fc_1): Linear(in_features=2, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lstm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de83f0",
   "metadata": {},
   "source": [
    "Choose loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fabab4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "14b3ea44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3471, dtype=torch.float64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550a5f9",
   "metadata": {},
   "source": [
    "Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b6d8faf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[210], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 2\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlstm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#forward pass\u001b[39;00m\n\u001b[0;32m      3\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m#caluclate the gradient, manually setting to 0\u001b[39;00m\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;66;03m# obtain the loss function\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[202], line 21\u001b[0m, in \u001b[0;36mLSTM1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m c_0 \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)) \u001b[38;5;66;03m#internal state\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Propagate input through LSTM\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m output, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#lstm with input, hidden, and internal state\u001b[39;00m\n\u001b[0;32m     22\u001b[0m hn \u001b[38;5;241m=\u001b[39m hn\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size) \u001b[38;5;66;03m#reshaping the data for Dense layer next\u001b[39;00m\n\u001b[0;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(hn)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  outputs = lstm1.forward(input_data.double()) #forward pass\n",
    "  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    " \n",
    "  # obtain the loss function\n",
    "  loss = criterion(outputs, target_data.double())\n",
    " \n",
    "  loss.backward() #calculates the loss of the loss function\n",
    " \n",
    "  optimizer.step() #improve from loss, i.e backprop\n",
    "  if epoch % 100 == 0:\n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
